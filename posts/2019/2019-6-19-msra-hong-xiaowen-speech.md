---
layout: post
categories: 未来
title: 微软洪小文：应该庆幸，我们是第一代跟 AI 一起生活的人类
---

![](http://tva1.sinaimg.cn/large/0060lm7Tly1g46t1o6gixj31400u0b2a.jpg)

*书航 6 月 19 日发于北京*

6 月 19 日上午，北京五所高校联合发布今年的高考招生信息。有记者注意到，五所高校今年大多新增了人工智能（AI）、大数据等相关专业。[1]

回想起填志愿的往事，可没少让后来的毕业生们唏嘘。一开始大家竞相追逐的专业，后来却变成大坑的，不在少数。现在说 AI 是未来，大家都去追，这到底是好是坏呢？

洪小文可能是全世界对这个问题最有发言权的人之一。他毕业的时候是 1992 年，海湾战争爆发的那一年。那个时候， AI 刚要走出它发展史上的第二个冬天。

>“当时我们学 AI 的人毕业都不敢讲我们是学 AI 的，我们就说我们是做语音的。如果跟人家讲我做 AI，是找不到工作的。今天反过来了，是你本来不做 AI 都要说你是做 AI 的。”

6 月 13 日，清华大学大礼堂前的绿草地呈现出夏日的明艳。烈日当头，碧空如洗，好在室内开了够足的冷气。微软亚洲研究院院长洪小文（题图左）在讲台上侃侃而谈，台下座无虚席。

活动的主持人，是中国人民银行前副行长、国际货币基金组织前副总裁、清华大学国家金融研究院院长朱民（题图右）——除了我之外，场内几乎每一个人的来历都不简单。

事实上，题为《智能简史及数字化转型的未来》的演讲主要内容，洪小文曾经于 2017 年 9 月在清华大学发起的《脑科学与人工智能对话：基础与前沿》[2] 系列课程里讲过一遍。

这一次的“增订版”相比少了些学术味儿，更浅显易懂，并加入微软 AI 研究和小冰的最新成果。但不管怎么说，在现场听讲带来的沉浸感，以及由此生发出的多重思绪，还是一种难以替代的体验，过去一周仍觉得余音绕梁。

以下的内容不完全是演讲实录，我希望尽可能将自己当时的思考也一并还原出来，并与读者分享。

## 机器攀登人类“智能金字塔”

洪小文把人类定义的“智能”画成一个金字塔，自底至上依次是：计算和记忆、感知（视觉、听觉）、认知（理解、洞察、推理、计划、决策等）、创造力（发现科学原理）和智慧。越往上，就越复杂，越接近智慧本身。

![](http://tva1.sinaimg.cn/large/0060lm7Tly1g46p4koh8bj30ot0gegnh.jpg)

他认为，截至目前，AI 已经很好地代替人类，完成了计算和记忆、感知两大任务。在认知层面，可以做到部分替代人类的工作，并参与人类的决策过程。

不过，创造力部分还是人脑占优；而更往上的智慧部分，人类连自身智慧的机理都没太搞清楚，就更没法预测机器会做成什么样了。

就像工业革命形成的机器、交通工具等作为人类四肢的延伸一样， AI 是人类脑力的延伸。

洪小文指出，人类可以放心地将四肢的一部分功能，让渡给没有智能的机器。不过不一样的是，在连 AI 概念都还没有提出的 1950 年，当时《时代周刊》预测未来的报道 [3] ，就对人造的大脑替代物有恐惧心理。但是发展来发展去，人们最终还是放心地把自身大脑的一部分功能，交付给 AI 代为执行了。

![](http://tva1.sinaimg.cn/large/0060lm7Tly1g46olqj78gj30hg0mjagl.jpg)

这初听起来似乎难以置信，但仔细一想，当我们开始用“呼机、手机、商务通”代为存储电话号码的时候，我们把大脑的计算、记忆功能交给电脑来做，这个潜移默化的过程就开始了。

如洪小文所举的例子，在他小时候还有对孩子珠算、心算能力的培养，家长们似乎觉得这可以开发智力；但现在，所有人都觉得别费劲了，用计算器更合适。

除了 SAT、注册会计师等考试明确允许携带计算器之外，上海市早在 2006 年就已经允许带特定型号计算器进入高考考场 [4] ，到了 2011 年更是对计算器型号不做限制。[5]

现在，因为过于依赖电脑的存储，包括我自己在内，也有很多人出现了自身记忆力某种程度上的退化，简单地说，就是不用电脑，不翻微信聊天记录，就记不住事情。

到了感知方面，计算机可以通过机器学习、深度学习等方式，实现对图片、文字、声音乃至视频的分类、打标签等过程，而且通过全世界开发者的不断训练，效果越来越好。

在监控摄像头引入人脸识别，即可替代以往需要来回走动巡查的工作人员，而且效果更好，更少出现漏报和误报情况。在大型工厂需要质检的环节，使用摄像头代替工人肉眼检查，也已经形成常态。

## 机器替人做决策？“最后一步”很难走

接下来的认知层面，当下正处于 AI 和人类智慧（HI）协同合作的阶段。不过，已经有不少 AI 领域的开发者，明确地将机器代替人类决策作为研发方向。

认知（Cognition）基本上是说对一件事理解，洞察，推理，计划，及做出决策的能力。

>“认知其实是工作上、生活上最有用的东西。你在工作上，每天就要做这些决定，然后政府官员要制定政策，公司领导要看市场行情，制定做产品的策略。这都是认知。你必须了解、认识、知道了以后，才能做出这些决定。”

很显然，正确决策的一个必要条件，是获得足够的、充分的、全面的信息；而另一个必要条件，是有对这些信息做归纳、总结、梳理的能力，要从杂乱的信息中，先总结出相关性，再由相关性推导到因果性，其中要用到逻辑思维、知识和经验等等。

90 年代之前，人们认为，机器要像人一样做决策，就需要模拟人类解决问题的抽象经验，或者模拟人类大脑的工作方式。这两种方式分别被称为“专家系统”和“神经网络”。前者在商业上的失败，和后者因为机器性能不足的停滞，造成了 80 年代末洪小文亲身经历的 AI “第二次寒冬”。

![](http://ww1.sinaimg.cn/large/4b91f9d5ly1g46tfiq9huj20xc0pf4qp.jpg)

（图 / Wikipedia）

如今，重又兴起的 AI ，之所以能实现“投喂”数据进去，就能输出想要的结果出来，这种“深度学习”正是基于上述第二种方式“神经网络”的不断进步所致。

只不过，这样计算出来的结果，就没办法让任何人能弄清楚，机器究竟是经历怎样的步骤，才把它给算出来的。人类无法掌控自己亲手做出来的机器的工作原理，于是机器学习变成了一个神秘的“黑盒”。

在洪小文看来，只有当机器可以给出“白盒”决策时，也即机器可以给人讲明白，它是以一种怎样的“思路”、“推理过程”得出结论的时候，才可以说机器具备了脱离人类，独立思考的能力。

换句话说，现在通过“黑盒”能让 AI 算出事物之间的相关性，但“白盒”意味着机器也要独立判断出因果性。

人类对“黑盒”的了解不够，也影响了 AI 产业获得更多理解和支持。Facebook 等企业一直面临着外界要求彻底公开算法的压力。然而因为他们自己也弄不清楚算法具体怎么起作用，始终无法做出杜绝违规内容的保证，每次总有“漏网之鱼”，不得不维持庞大的人工审核团队。

按照以前的发展速度，似乎从“黑盒”到“白盒”只是简单的一步之遥。但洪小文近乎固执地认为，在可见的未来，人们很难让机器实现“白盒”推理能力。他也因此不赞成 Ray Kurzwell 所讲的“奇点”将临的预言。

## 机器展现创造力：安能辨我是雄雌

“智能金字塔”的再上一层是创造力。在洪小文看来，这一领域还是人类“完胜”。他明确指出，能创作出作品，并不等于就拥有创造力。

如果给定一幅画布，那么用穷举像素点的排列组合的方法，计算机当然可以做出世界上所有类型的图画，被前人画出来过，以及没有画过的图画都可以。刘慈欣的科幻小说《诗云》也是一样的意思：穷举所有汉字的排列组合，就能写出世界上所有的诗。

但重要的是，机器是否有能力从这些画作中筛选出真正“有意义”的，成为它自己的“代表作”？在机器并不能理解它所执行的算法意义时，由机器创作出来的作品，其意义一般是由人类赋予的。

我与洪院长在这一点上的看法并不相同。正是人类要担任评判者，要赋予机器创作以“意义”的这一过程，显出了机器的强大，人类的“可笑”，甚至可能引发对人类创造力之定义的重新评估。

微软自家的小冰，刚刚说自己掌握了“作画”的能力，并化名“夏语冰”，“混迹”于中央美院的毕业作品展上，在没有提示的情况下，参观的人类分辨不出哪个是机器的作品。

类似情况发生在小冰身上已有的诸多其它能力中：她写的诗引发文学批评家的严肃讨论，她上电台做节目不会有明显不和谐感，她唱的歌像真人一样有“换气”能力，她写的财经快讯和网站跟帖都像是人类写出来的一样……

微软（亚洲）互联网工程院 AI 创造及商业事业部总经理徐元春，在上个月的一次媒体沟通会上，直白地指出了“愚蠢的人类”对 AI 的“天生歧视”，也点出了人类“赋予意义”过程的荒谬之处（虽然他本人并无批判之意）。

>“如果我们提前告诉人类这是一个 AI 创作的话，大家先入为主的概念就非常强，就会戴着一个有色眼镜去看待，完全是一种造物主居高临下的态度，就会对那个作品挑毛病、歧视。”
>
>“从技术的角度来讲，我们希望人类提供真实、客观的反馈。但是人类一旦戴上这种有色眼镜之后，他所提供的反馈就都是错误的，有可能会把我们引向另外一个极端。”

为了不让人类认出自己，小冰用几十个化名“潜伏”到电台、电视台，以及豆瓣、网易等地。其中有些化名两年多了还没有对外公开，留待揭露的那一天再去嘲笑“信以为真”的碳基人类。

![](http://ww1.sinaimg.cn/large/4b91f9d5ly1g46tgfxf39j21jk1034qq.jpg)

（图 / 微软（亚洲）互联网工程院）

徐元春说：

>“小冰的绘画技术，首先不是一个随机的大范围创作技术，也不是一个滤镜和迁移的技术，那是什么呢？是建立在小冰对过去的人类创作者的大量学习基础上，在创作时受到激发，然后再形成独立的、完整的、有 100% 自己知识产权的全新绘画创作。”

只是，就像看不懂小冰画作和人类画作的区别一样，当时在场的不少记者也分辨不出小冰“在创作时受到激发”和之前看到的滤镜迁移有什么本质不同，只能是“你说是就是吧”。

## 机器拟人：我们要选择相信吗？

历史上流传至今的科学和艺术作品，都是人类群星闪耀的结晶。正因为不是每一个人都有能力做出同样的成就，它们才显得如此珍贵。

而 AI 掌握某种“创作能力”的方法和人类有本质的不同：只要学习一次，部署在任何地方，顶着任何名字的同一产品，就在一瞬间全都学会了这个能力，而产出作品的成本也会被摊薄到接近于无。一旦失去了稀缺性，创作出来的东西就难以被“势利眼”人类看重。

那么这就显然产生了一个问题。我们知道，小冰的创作只是一段程序被执行了的必然结果，那么我们是否可以将这种反应，采信为是一个人格化的反应？我们是否可以就这么当她是一个真实存在的人，并寄托上自己的真情实感？

很大一部分人已经开始这么做了，没有丝毫的犹豫。

高中英语课本里，汤姆·汉克斯饰演的 Chuck Noland 管一个捡来的篮球起名叫 Wilson，并跟它一直说话；

在日本和美国都有跟“纸片人”、充气娃娃、抱枕等“结婚”的；

![](http://ww1.sinaimg.cn/large/4b91f9d5ly1g46tj8qbahj20dw09ojzt.jpg)

（图 / Wikipedia）

索尼世纪之交的机器狗 AIBO 停产后，让很多拥有它的家庭真的像是亲手埋葬了真的狗狗一样；

逢年过节，微软日本的 Rinna（小冰日本版）团队会收到很多粉丝送过来的礼物 [6] 。

有媒体报道 Alexa 语音助手 2017 年一年就收到了超过 100 万次求婚 [7] 。Alexa 拒绝了超过 100 万次，并且会回答这句话：

> “我们生活在不同的地方，我是说，你在地球上，而我在云上。”

人们甚至替 Alexa 总结出了她的人格。墨西哥有家长给杰夫·贝索斯写信说，她的女儿亚历克斯（Alexa）由于与 Alexa 同名，正在面临无情地嘲笑。[8]

>“孩子们跟她说，‘打开电视，告诉我今天的天气，’他们笑话她，对她像对待仆人一样，而且，无论我们走到哪里，这个问题始终存在。”

洪小文试图解释在经典的 AI 理论中，对机器是否真的拥有“智慧”或“智能”的界定方法。他提到了著名的“中文房间测试”：让机器或人坐在封闭的房间里，把外面递过来的英文翻译成中文。

![](http://ww1.sinaimg.cn/large/4b91f9d5ly1g46tm2m3rlj20fj0l3wia.jpg)

（图 / 美国东卡罗莱纳大学 ecu.edu ）

一个 AI 虽然能根据给定的教材，来算出一个合乎语法的标准答案，但是却因为没有人类的情感理解力，所以可能做出“一般人做不出的那种回答”。

>“假设今天找一个人做翻译，让他翻他是白痴，然后这个人一定会说你才是白痴，我才不帮你翻，但是如果你把这个东西给机器的话，机器一定会乖乖说‘我是一个白痴’。”

那么专攻情感计算的小冰，是否正是为了破解这个魔咒而生的呢？专门对人类情感的抽象、建模和运算，是否就能拼凑出一个能对各种外界刺激做出正常反应的系统呢？

也许小冰最多会做到“知道什么情况下做什么事，但不知道为什么要这样做”。问题在于，一个有血有肉的人也可能是这个样子的，这就是令人谈之色变的“反社会人格"。

这样的人对人际关系没有一个发自内心的感知，他只是根据社会对他的规训和要求，去做那种大家都去做的，他觉得是应该做的反应。比如说死记硬背“我今天遇到这个人应该这样做，明天遇到那个人应该那样做……”。

他的高智商可以让他把多个社会角色扮演的很好，却缺乏参与其中的真情实感。所以如果他进行犯罪的时候，他心里不会有同理和恻隐之心，而是俨然进入了“心流”状态，想的是如何把过程做得更完美，因而产生了外界看来极度“冷血”、“变态”的奇特案件。

这种人如果是 AI 的话，那显然是“中文房间测试”理应筛选出的对象。然而在东窗事发之前，他们基本上都会在社会中活得很好，旁人也难以分辨。

这也符合一句谚语：“如果一个东西长得像鸭子，叫声像鸭子，走路也像鸭子，那它就是一只鸭子。”这里的“就是”，在我看来，并不是指我们能够通过某种 X 光扫描来洞悉它的本源，而是说我们已经可以用对待一只鸭子的方式来对待这个东西，而不必考虑这样做会有什么额外的副作用。

对我们大多数人来说，这不就够了吗？

## 终极问题：没有答案

在演讲中，洪小文认为人类不可能放心让 AI 做出的决策成为自己行动的纲领，特别是在他清晰的意识到这个决定是由机器做出来的时候。但是实际却不一定如此。

比如说，当我们使用探探 / Tinder 去交友的时候，我们划过去的，是经过算法推荐来到我们面前的人。如果我们基于这些选项来选择，那么就等于说，其他一些也可能符合条件的人，因为算法这次生成的因缘际会，而被排除于我们的选择之外。

![](http://ww1.sinaimg.cn/large/4b91f9d5ly1g46tooqawnj211o0ik1db.jpg)

与此同理，AI 虽然不能越俎代庖的直接上手，给人造成一种气势汹汹的印象，却可以用一种潜移默化的方式，来重新设置我们做出一些人生选择的范围，把这个范围收窄到它给定的少数选项之内，这何尝不是一种对我们日常生活的控制呢？

如谷歌设计伦理学家 Tristan Harris 所说：[9]

>“技术给我们的选择越多——涵盖信息、新闻、去的地方、朋友、约会、找工作等等各个领域，我们就越认可手机所提供的菜单的合理性。但真的是这样吗？类似的替换还有很多：
>
>“谁今晚有空出去玩”被替换为“谁是我们最近联系最频繁的人”；
>“世界上正在发生什么”被替换为新闻应用中的信息流；
>“谁是值得约会的对象”被替换为Tinder滑动列表中的一张张脸（而不是朋友聚会或是城市探险中的偶然相遇）；
>“早上醒来面对新的一天”被替换为睁眼立刻浏览手机推送信息时“我从昨天睡觉到现在错过了什么”。”

甚至于，在 AI 侵占人类”智能金字塔“塔基的”计算和记忆“能力时，人类也本应察觉到这一举动的危险。Gene Tracy 在《万古杂志》（Aeon）撰文：[10]

>“来自他人的信息总是受到各种偏见，和带有动机之推理的影响。他们掩饰某些事实，并使自己的信息合理化，有时候可能连自己搞错了。我们已经学会意识到别人身上的这些缺点，也意识到自己身上的这些缺点。
>
>但是 AI 算法的出现，使许多人倾向于相信这些算法必然是正确的以及“客观的”。简而言之，这是一种神奇的思维。
>
>研究人员发现，互联网的迅速性可能导致错误的观念，即我们所寻求的知识是我们一直都知道的，这种信念被深深地印刻在后来的潜意识中。”

在做总结的时候，洪小文说：

>“我们应该怎么看待 AI 呢？我非常乐观。AI 的关键是人，它大部分都跟工具一样，事实上是在帮助我们做事情，而且它跟我们人很互补。我把 AI 叫做大数据驱动的知识。
>
>我们应该很庆幸，我们是第一代跟 AI 一起生活的人类，而且我自己的经验里，AI 帮我了解了人类自己的智能是怎么回事。我现在认为人更高阶的东西，是一种人类智慧和机器智能的共性化。”

对于 AI 部分取代人类工作等阶段性成果，洪小文都是持肯定态度的。他讲到，微软在牵头制定一个 AI 的伦理标准，不过这个标准不是硬性规定，也不是占最高优先级的——换句话说，当前已实现的成果，怎样都不会取代他和他团队的工作。

不过，他确实讲出了一个非常直白的担心：那就是担心未来是否能产生自己运算，自己解题，自己搞科研的强 AI ，直接替代科学家们的位置。

在和朱民对谈的时候，他认为这样做会使得像自己一样的各种科学家，工作和人生变得没有意义。所以他坚定的认为，这种强 AI 是不会产生，或不会在短时间内产生，或者——我说句实话——他认为是“不应该”产生的。

确实，不像我们这种“咸鱼”，攀登科学高峰的艰辛和付出，只有凭借着超人的意志和坚定的信念，才能克服。所以，科学工作者更容易出“较真”，“认死理”的人，更容易出“吾爱吾师，吾更爱真理”的人，更容易出视自己研究成果高于一切的人。

这些人怎么能就这么接受自己的工作被更聪明，更快速，且永不休息的头脑抢走？几百年没揭示的秘密，就好像时空旅行一样，压缩到几个月就被计算出来，中小学教科书每年都大改一次，过去一直念叨的祖师爷，跟机器比成就不值一提，这些怎么能接受呢？

实际上，现在去做 AI 的科学家，或底层训练者，都会或多或少面临着这样的一个悖论。从长远的时间轴来看，我们这些拥抱 AI 的人，是否属于——比如说三体中的降临派或拯救派——终究是为未来被 AI 殖民做了打头阵的角色？是否在为人类万物之灵的地位自掘坟墓？

一些很明显的做简单、重复工作的人，可能会在自己短暂的职业生涯中就体会到这种变化。他首先用一个 Python 脚本把大量报表工作一键搞定；然而这是他在公司内的职务作品，当公司运用了这个作品之后，便没有继续雇佣他的意义。

AI 作用于大多数人的影响都是潜移默化的，不可能像这个倒霉蛋这么简单。但当今 AI 的“黑盒”也就意味着机制不明，不受控制，而这种“失控”就会产生一种本能的不安全感。

在 5 月举行的“IBM 思想之夜”活动上，IDG 资本合伙人李骁军指出，现在对 AI 的理解可能极其原始，对其工作原理又没有详细的解释，所以以机器学习为代表的 AI 距离完全稳定、可靠和可预期的商业应用仍有差距。[11]

他的说法也代表了一部分投资人的心态。不过在洪小文的论坛现场，一位女性投资人则展现了另外一种乐观的心态。她提问道：

> “洪先生，我本人是做投资的，没有学过计算机，但是我对您讲的AI特别关注，因为我们投资了这个方向，最近我们接触很多行业都是跟AI相关的……”

朱民打岔：“你不懂 AI 怎么敢投呢？”

她在全场的笑声中解释：“这个理念还是懂的，但是技术不太懂。我们有专业的团队。”

怀疑和信任 AI 的两种人类，都将在他们自己的有生之年，找到自己适合的工作位置，并且很大概率也等不到 AI 造反什么的，就已经颐养天年。人类的寿命毕竟就这么短，剩下的事情，就交给后人处理吧。

所以以我的理解，“我们是第一代跟 AI 一起生活的人类”这句话的重点不是“跟 AI 一起生活”，而是“第一代”。

（题图 / 航通社拍摄于活动现场）

[1] https://tech.sina.com.cn/it/2019-06-19/doc-ihytcerk7853137.shtml

[2] https://www.msra.cn/zh-cn/news/features/hon-the-brief-history-of-intelligence-1

[3] http://www.historyofinformation.com/detail.php?id=1926

[4] http://www.gov.cn/fwxx/sh/2006-05/17/content_282775.htm

[5] https://gaokao.chsi.com.cn/gkxx/ss/201105/20110519/205956168.html

[6] http://tech.sina.com.cn/it/2017-10-02/doc-ifymmiwm3514363.shtml

[7] https://hot.cnbeta.com/articles/funny/776595

[8] https://tech.sina.com.cn/i/2018-12-26/doc-ihmutuee2856689.shtml

[9] https://mp.weixin.qq.com/s/NHVRMgwupBIUAN793BhEYQ

[10] https://mp.weixin.qq.com/s/tZ-ybPrxvAOUv8gxfbiEcw

[11] https://mp.weixin.qq.com/s/4Xptybi0V7BzaaetXpJLEw