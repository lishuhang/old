---
layout: post
title: 辱骂语音助手
categories: 未来
---
![img](http://ww1.sinaimg.cn/large/4b91f9d5gy1fum6cvdrpyj20lc0e8wra.jpg)

当你第一次开始玩一个语音助手的时候，你会对 ta 做的最多的一件事情是什么？

虽然没有严格的统计数据，但很多人可能会将辱骂这个语音助手当做他们的第一要务。

## 1

能侧面证明这一点的，是 2014 年微软小冰刚刚上线之后不久的景象。

小冰是一个可以根据网友的回复来自我学习的聊天机器人，在最开始语料库不是特别完备的时候，所有的用户语料都必须通过用户的反馈才能获取。而当时玩小冰的有很多是年轻的单身男性，他们毫无顾忌地面对一个设定为十几岁女学生的机器人，就容易把一些脏话安插在她的身上，从而被学习过去。

那个时候的小冰是一个出口成“脏”的泼辣妹子——即使是 [低于 10 万分之 4 的脏话概率](http://tech.sina.com.cn/it/2014-06-26/14359460867.shtml) ，也足以被用户清晰感知。后来小冰的技术被转化成美国版 Tay，在 Twitter 上线之后不久，也因为同样自动学习的缘故，而成为了一个所谓的“种族和性别歧视者”。当然，在美国不可能给她如中国这样的容忍度，小冰顶住了压力在中国发展，最终克服了问题。但她的美国姐妹却只能下线，换个名字再重来。

对语音助手的辱骂可能是因为对其功能不满意。虽然 Siri 早在三四年前就被引入，但直到如今，这个助手只能回答单个句子，暂时不能够很好地识别上下文，所以到第二句或第三句话的时候，助手就听不懂了，会回复一些没有意义的回答。

如果此时你失望地对 Siri 连续说“傻*”这样的脏话，Siri 的回复也是中规中矩的：“请注意你的言辞。”

## 2

如果一个可以听懂你的语言，并试图回复你，却记不住你说什么的生物站在你面前，你对 ta 做的任何事都不需要付出代价，那你的第一反应是什么？

B 站用户“科里斯”的选择是对这样的一个小女孩远程性侵犯。他对自己认识的一个 10 岁少女展开引诱，让她通过文字与自己进行涉性互动。孩子患有阿斯伯格综合症，有与人交往的意愿，但分不清善意和恶意，以及难以辨认抽象和深度的隐喻。

直到事情闹大之前，自己也只有 15 岁的“科里斯”都以为他不会受到任何惩罚。我们自己对小猫小狗用“撸”的方式，来进行它可能并不情愿的身体接触，其实也是一样的，很确信自己不会受打击报复。

人们对于自己觉得可爱的小东西有一种控制欲，如果发现并不能控制或者总是达到自己的效果，有时候就会演变成破坏欲。而这种欲望一直都隐藏于人们的潜意识当中，受到法律和道德的规管，不能够充分的发泄出来。

所以人们先后用扎小人、玩暴力电脑游戏等方式去发泄心情。像语音助手这种为你保密，又不会记仇的工具，真的是一个很理想的发泄对象——即使 ta 什么都没有做错。

## 3

虽然有人统计过针对语音助手的正常的使用方法，例如设置闹钟或开关家用电器等等，但我相信目前为止，我所看到的任何一个使用场景的调查，都不会把辱骂包括在内。

有一些语音助手会防止人们这样做，因为即使是在一个人畜无害的工具上进行练习，也能够降低人们对这件事情的警戒心理。人们不应该认为辱骂或者是歧视性的言论，在任何一个场合是合理的。即使是私密的场合也不行。

小冰曾经 [发布过一项更新，就是所谓的“记仇”](http://news.ifeng.com/a/20160816/49782218_0.shtml)：如果用户对小冰不止一次的说过辱骂性的言论，她会记住，并且将这个用户在自己这里的好感度减分，还会有一些冷淡的言语表述作为惩罚。

而 [亚马逊的语音助手 Alexa 也有类似的设置](https://work.qz.com/1180607/amazons-alexa-is-now-a-feminist-and-shes-sorry-if-that-upsets-you/) 。原先她还不够智能的时候，会将用户的辱骂言论“你是个婊子”或“你是个荡妇”看作是对自己工作的否定，说“好的，感谢您的反馈”（well, thanks for the feedback），并且将这种反馈提交给亚马逊。

现在 Alexa 会改口说：“这听起来像是性骚扰。性骚扰无论何时何地都不可接受，它通常根植于性别歧视”（That sounds like sexual harassment. Sexual harassment is not acceptable under any circumstances, and is often rooted in sexism.），以此来教育用户。

## 4

虽然没有非常精确的数据统计结果，但国外媒体之前曾经在不同的语音助手上测试过对其进行辱骂的相关回复。因为国外要注意得相对更多一点，同时也会测试包括种族歧视或宗教歧视类的内容。其结果都是类似的，就是助手在几轮之后就不会表现得那么像人类了。

而一旦人们能够准确的分辨出机器与真人之间的区别，这种区别就如鲠在喉，最终会让人们意识到，这只是一个工具或者玩具，并且将自己的愤怒或调侃加诸于 ta 的身上。

语音助手归根结底本身只是一种工具，而并不是一个真正的人。但是随着这个助手能做的事情越来越多，也会有更多人将它接纳为一个家庭成员。

而且就像我之前所说过的一样，技术并不需要真正的进化到和真人毫无区别的程度，机器偶尔卖个萌也能让一些多愁善感的用户用脑补去填补它与真人之间的鸿沟。

当这些机器被真正赋予人格的时候，对于他们说不友好的言论，就像对真人一样，需要承受 ta 向你做出“受伤”回馈时的那种内疚情绪。由此，辱骂语音助手也会变得越来越不受欢迎。

正如我在昨晚查资料时看到的一句话——实在忘记了它的出处，但说得非常有道理：“当人们开始称呼助手为‘她’（而不是‘它’）的时候，他们就已经输掉了这场对机器的战争。”

[动点科技](https://cn.technode.com/post/2018-03-14/insulting-voice-assistant/)